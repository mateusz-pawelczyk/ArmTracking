{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 13:35:28.110237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 13:35:31.760598: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-09-11 13:35:31.762068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-09-11 13:35:32.086458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.57GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2024-09-11 13:35:32.089699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.56GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2024-09-11 13:35:32.089727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-09-11 13:35:32.090965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-09-11 13:35:32.091029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-09-11 13:35:32.092152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-09-11 13:35:32.092373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-09-11 13:35:32.093532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-09-11 13:35:32.094169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-09-11 13:35:32.096594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-09-11 13:35:32.112821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available_\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-Daten laden (ersetze 'your_data_file.csv' mit dem tatsächlichen Dateinamen)\n",
    "df = pd.read_csv('csv/processed_Trajectories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere die relevanten Daten (Schulter, Ellbogen, Handgelenk, ThumbTip)\n",
    "shoulder = df[['Tasch:shoulder:X (mm)', 'Tasch:shoulder:Y (mm)', 'Tasch:shoulder:Z (mm)']].values\n",
    "elbow = df[['Tasch:elbow:X (mm)', 'Tasch:elbow:Y (mm)', 'Tasch:elbow:Z (mm)']].values\n",
    "wrist = df[['Tasch:wrist:X (mm)', 'Tasch:wrist:Y (mm)', 'Tasch:wrist:Z (mm)']].values\n",
    "thumb_tip = df[['Tasch:ThumbTip:X (mm)', 'Tasch:ThumbTip:Y (mm)', 'Tasch:ThumbTip:Z (mm)']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisierung der Daten\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_all = np.vstack([shoulder, elbow, wrist])\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "# Split the scaled data back into shoulder, elbow, and wrist\n",
    "shoulder = X_all_scaled[:len(shoulder)]\n",
    "elbow = X_all_scaled[len(shoulder):len(shoulder) + len(elbow)]\n",
    "wrist = X_all_scaled[len(shoulder) + len(elbow):]\n",
    "\n",
    "# Scale the thumb_tip data separately\n",
    "thumb_tip = scaler.fit_transform(thumb_tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine shoulder, elbow, wrist into the features (X)\n",
    "X_train = np.hstack([shoulder, elbow, wrist])\n",
    "\n",
    "# The target variable is thumb_tip (Y)\n",
    "Y_train = thumb_tip\n",
    "\n",
    "# Convert your NumPy arrays to TensorFlow datasets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "\n",
    "# Set the dataset options and auto-shard policy to DATA\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "dataset = dataset.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(32).shuffle(buffer_size=len(X_train)).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "# Define the strategy for using multiple GPUs\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))  # Should print 2 if 2 GPUs are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # Define the model inside the strategy scope\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(3)  # Predicting X, Y, Z position of ThumbTip\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',                 # Adam optimizer\n",
    "        loss='mean_squared_error',         # Mean squared error for regression\n",
    "        metrics=['mean_absolute_error']    # Optional metric for monitoring\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 13:53:47.456270: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_607820\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "1191/1198 [============================>.] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.0750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 13:53:54.024015: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_611802\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 9s 6ms/step - loss: 0.0216 - mean_absolute_error: 0.0748 - val_loss: 0.0020 - val_mean_absolute_error: 0.0313\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 9.5259e-04 - mean_absolute_error: 0.0208 - val_loss: 0.0013 - val_mean_absolute_error: 0.0251\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 8.0839e-04 - mean_absolute_error: 0.0190 - val_loss: 0.0013 - val_mean_absolute_error: 0.0251\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 7.5976e-04 - mean_absolute_error: 0.0184 - val_loss: 0.0013 - val_mean_absolute_error: 0.0236\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 7.0989e-04 - mean_absolute_error: 0.0177 - val_loss: 0.0012 - val_mean_absolute_error: 0.0218\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 7.1466e-04 - mean_absolute_error: 0.0177 - val_loss: 0.0018 - val_mean_absolute_error: 0.0304\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.6813e-04 - mean_absolute_error: 0.0172 - val_loss: 0.0013 - val_mean_absolute_error: 0.0237\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.6634e-04 - mean_absolute_error: 0.0169 - val_loss: 0.0011 - val_mean_absolute_error: 0.0221\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.5546e-04 - mean_absolute_error: 0.0169 - val_loss: 0.0010 - val_mean_absolute_error: 0.0214\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.5157e-04 - mean_absolute_error: 0.0169 - val_loss: 0.0013 - val_mean_absolute_error: 0.0245\n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.2966e-04 - mean_absolute_error: 0.0165 - val_loss: 0.0011 - val_mean_absolute_error: 0.0221\n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.2251e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0018 - val_mean_absolute_error: 0.0271\n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 6.0786e-04 - mean_absolute_error: 0.0161 - val_loss: 0.0021 - val_mean_absolute_error: 0.0329\n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.7804e-04 - mean_absolute_error: 0.0159 - val_loss: 0.0011 - val_mean_absolute_error: 0.0217\n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.9830e-04 - mean_absolute_error: 0.0159 - val_loss: 0.0013 - val_mean_absolute_error: 0.0230\n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.8724e-04 - mean_absolute_error: 0.0159 - val_loss: 0.0011 - val_mean_absolute_error: 0.0214\n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.4735e-04 - mean_absolute_error: 0.0154 - val_loss: 0.0011 - val_mean_absolute_error: 0.0211\n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.5545e-04 - mean_absolute_error: 0.0153 - val_loss: 0.0013 - val_mean_absolute_error: 0.0228\n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.4611e-04 - mean_absolute_error: 0.0152 - val_loss: 0.0012 - val_mean_absolute_error: 0.0213\n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.2843e-04 - mean_absolute_error: 0.0149 - val_loss: 0.0011 - val_mean_absolute_error: 0.0216\n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.3852e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0013 - val_mean_absolute_error: 0.0225\n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.3353e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0017 - val_mean_absolute_error: 0.0278\n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.3298e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0013 - val_mean_absolute_error: 0.0246\n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.2896e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0015 - val_mean_absolute_error: 0.0242\n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.2892e-04 - mean_absolute_error: 0.0151 - val_loss: 0.0013 - val_mean_absolute_error: 0.0225\n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.0249e-04 - mean_absolute_error: 0.0146 - val_loss: 0.0014 - val_mean_absolute_error: 0.0240\n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.0007e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0012 - val_mean_absolute_error: 0.0217\n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 5.0191e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0017 - val_mean_absolute_error: 0.0280\n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.8014e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0014 - val_mean_absolute_error: 0.0233\n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.9879e-04 - mean_absolute_error: 0.0145 - val_loss: 0.0013 - val_mean_absolute_error: 0.0228\n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.9020e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0015 - val_mean_absolute_error: 0.0255\n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.8912e-04 - mean_absolute_error: 0.0144 - val_loss: 0.0012 - val_mean_absolute_error: 0.0212\n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.8377e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0013 - val_mean_absolute_error: 0.0233\n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.8729e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0013 - val_mean_absolute_error: 0.0236\n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.8633e-04 - mean_absolute_error: 0.0143 - val_loss: 0.0011 - val_mean_absolute_error: 0.0210\n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.6950e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0014 - val_mean_absolute_error: 0.0232\n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.6358e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0014 - val_mean_absolute_error: 0.0231\n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.6864e-04 - mean_absolute_error: 0.0141 - val_loss: 0.0014 - val_mean_absolute_error: 0.0243\n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.6918e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0014 - val_mean_absolute_error: 0.0224\n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.5751e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0015 - val_mean_absolute_error: 0.0233\n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.5582e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0014 - val_mean_absolute_error: 0.0237\n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.5326e-04 - mean_absolute_error: 0.0138 - val_loss: 0.0014 - val_mean_absolute_error: 0.0238\n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.4705e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0015 - val_mean_absolute_error: 0.0238\n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.4985e-04 - mean_absolute_error: 0.0137 - val_loss: 0.0015 - val_mean_absolute_error: 0.0251\n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.4400e-04 - mean_absolute_error: 0.0135 - val_loss: 0.0019 - val_mean_absolute_error: 0.0299\n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.4110e-04 - mean_absolute_error: 0.0135 - val_loss: 0.0015 - val_mean_absolute_error: 0.0254\n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.5502e-04 - mean_absolute_error: 0.0139 - val_loss: 0.0011 - val_mean_absolute_error: 0.0212\n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.4348e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0014 - val_mean_absolute_error: 0.0234\n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.2570e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0012 - val_mean_absolute_error: 0.0227\n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.3347e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0014 - val_mean_absolute_error: 0.0238\n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.2197e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0012 - val_mean_absolute_error: 0.0221\n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.3324e-04 - mean_absolute_error: 0.0136 - val_loss: 0.0013 - val_mean_absolute_error: 0.0222\n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.2028e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0013 - val_mean_absolute_error: 0.0238\n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.2436e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0013 - val_mean_absolute_error: 0.0248\n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.2106e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0015 - val_mean_absolute_error: 0.0251\n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.1821e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0013 - val_mean_absolute_error: 0.0216\n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.1156e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0013 - val_mean_absolute_error: 0.0226\n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.1355e-04 - mean_absolute_error: 0.0132 - val_loss: 0.0011 - val_mean_absolute_error: 0.0214\n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.0435e-04 - mean_absolute_error: 0.0131 - val_loss: 0.0013 - val_mean_absolute_error: 0.0212\n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.2512e-04 - mean_absolute_error: 0.0134 - val_loss: 0.0014 - val_mean_absolute_error: 0.0233\n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.1543e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0010 - val_mean_absolute_error: 0.0201\n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 4.1172e-04 - mean_absolute_error: 0.0133 - val_loss: 0.0013 - val_mean_absolute_error: 0.0228\n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 3.9150e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0013 - val_mean_absolute_error: 0.0229\n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 3.8823e-04 - mean_absolute_error: 0.0127 - val_loss: 0.0011 - val_mean_absolute_error: 0.0203\n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 3.8966e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0012 - val_mean_absolute_error: 0.0217\n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 3.8891e-04 - mean_absolute_error: 0.0128 - val_loss: 0.0015 - val_mean_absolute_error: 0.0247\n",
      "Epoch 67/100\n",
      " 454/1198 [==========>...................] - ETA: 2s - loss: 4.0399e-04 - mean_absolute_error: 0.0130"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modell trainieren\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history_gpu \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Visualisiere die Verlustkurve\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_gpu\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1105\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 454\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(callback, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m numpy_logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:511\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    510\u001b[0m   x \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 511\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3153\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_ndim_dispatcher)\n\u001b[1;32m   3122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mndim\u001b[39m(a):\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;124;03m    Return the number of dimensions of an array.\u001b[39;00m\n\u001b[1;32m   3125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3151\u001b[0m \n\u001b[1;32m   3152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3153\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m   3155\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Modell trainieren\n",
    "history_gpu = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Visualisiere die Verlustkurve\n",
    "plt.plot(history_gpu.history['loss'], label='Train Loss')\n",
    "plt.plot(history_gpu.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Verlustkurve während des Trainings')\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('Verlust')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielhafte Vorhersage mit neuen Eingaben (simulierte Daten, ersetze durch tatsächliche Werte)\n",
    "new_shoulder_position = np.array([[0.2, 0.3, 0.4]])  # Normalisierte Eingabe\n",
    "new_elbow_position = np.array([[0.3, 0.4, 0.5]])     # Normalisierte Eingabe\n",
    "new_wrist_position = np.array([[0.4, 0.5, 0.6]])     # Normalisierte Eingabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kombiniere die neuen Eingaben\n",
    "new_input = np.hstack([new_shoulder_position, new_elbow_position, new_wrist_position])\n",
    "\n",
    "# Vorhersage der ThumbTip Position\n",
    "predicted_thumb_tip = model.predict(new_input)\n",
    "print(f\"Vorhergesagte ThumbTip Position: {predicted_thumb_tip}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
